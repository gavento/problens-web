#!/usr/bin/env python3
"""
Master script to run all compression experiments and update the widget.
Computes ZIP, letter-wise optimal, and GPT-2 compression on all text samples.
"""

import json
import math
import gzip
import zipfile
import os
import tempfile
from pathlib import Path
from datetime import datetime
from collections import Counter

# Removed GPT-2 imports as we won't run it here


def load_text_samples():
    """Load text samples from list.json configuration."""
    texts_dir = Path("texts")
    list_file = texts_dir / "list.json"
    
    if not list_file.exists():
        raise FileNotFoundError(f"Text list file not found: {list_file}")
    
    with open(list_file, 'r') as f:
        sample_configs = json.load(f)
    
    samples = {}
    for config in sample_configs:
        filename = config["filename"]
        filepath = texts_dir / filename
        
        if not filepath.exists():
            print(f"âš ï¸  Warning: {filepath} not found, skipping")
            continue
        
        with open(filepath, 'r', encoding='utf-8') as f:
            text = f.read().strip()
        
        # Use filename without extension as key
        key = filepath.stem
        samples[key] = {
            "text": text,
            "name": config["name"],
            "description": config["description"],
            "filename": filename
        }
        print(f"âœ… Loaded {key}: {len(text)} characters")
    
    return samples


def compute_letter_wise_optimal(text):
    """Compute theoretical optimal compression using character entropy."""
    if not text:
        return 0
    
    # Count character frequencies
    char_counts = Counter(text)
    total_chars = len(text)
    
    # Compute entropy: -sum(p_i * log2(p_i))
    entropy = 0.0
    for count in char_counts.values():
        p_i = count / total_chars
        entropy -= p_i * math.log2(p_i)
    
    # Total bits needed = entropy * number of characters
    total_bits = entropy * total_chars
    return total_bits


def compute_zip_compression(text):
    """Compute ZIP compression size."""
    if not text:
        return 0
    
    text_bytes = text.encode('utf-8')
    
    # Create temporary zip file
    with tempfile.NamedTemporaryFile(suffix='.zip') as tmp_file:
        with zipfile.ZipFile(tmp_file.name, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            zip_file.writestr('data.txt', text_bytes)
        
        # Get compressed size (subtract ZIP overhead for more accurate comparison)
        compressed_size = os.path.getsize(tmp_file.name)
        # Approximate ZIP overhead: ~30 bytes for headers
        return max(compressed_size - 30, 1) * 8  # Convert to bits


# GPT-2 compression removed - will be run separately


def run_all_experiments():
    """Run all compression experiments and save results."""
    print("ğŸš€ Running All Compression Experiments")
    print("=" * 60)
    
    # Load text samples
    print("\nğŸ“„ Loading text samples...")
    samples = load_text_samples()
    
    if not samples:
        print("âŒ No text samples found!")
        return
    
    # GPT-2 model initialization removed
    
    # Run experiments on each sample
    results = {}
    
    print(f"\nğŸ§® Processing {len(samples)} text samples...")
    print("=" * 60)
    
    for key, sample in samples.items():
        text = sample["text"]
        print(f"\nğŸ“Š Processing: {sample['name']}")
        print(f"   File: {sample['filename']}")
        print(f"   Length: {len(text)} characters")
        
        try:
            # Compute all compression methods
            naive_bits = len(text) * 8
            letterwise_bits = compute_letter_wise_optimal(text)
            zip_bits = compute_zip_compression(text)
            
            # Calculate ratios
            letterwise_ratio = naive_bits / letterwise_bits if letterwise_bits > 0 else 1.0
            zip_ratio = naive_bits / zip_bits if zip_bits > 0 else 1.0
            
            print(f"   ğŸ“ˆ Naive: {naive_bits} bits (1.00x)")
            print(f"   ğŸ“ˆ Letter-wise: {letterwise_bits:.0f} bits ({letterwise_ratio:.2f}x)")
            print(f"   ğŸ“ˆ ZIP: {zip_bits} bits ({zip_ratio:.2f}x)")
            
            results[key] = {
                "name": sample["name"],
                "description": sample["description"],
                "filename": sample["filename"],
                "text_length": len(text),
                "naive_bits": naive_bits,
                "letterwise_bits": round(letterwise_bits),
                "zip_bits": zip_bits,
                "gpt2_bits": naive_bits,  # Placeholder - same as naive
                "letterwise_ratio": round(letterwise_ratio, 2),
                "zip_ratio": round(zip_ratio, 2), 
                "gpt2_ratio": 1.0,  # Placeholder ratio
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"   âŒ Error processing {key}: {e}")
            results[key] = {
                "name": sample["name"],
                "description": sample["description"],
                "filename": sample["filename"],
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    # Save results
    output_file = "compression_results.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ Results saved to: {output_file}")
    
    # Print summary
    print("\nğŸ“‹ COMPRESSION SUMMARY")
    print("=" * 60)
    
    successful = [k for k, v in results.items() if "error" not in v]
    if successful:
        print("Algorithm performance across all samples:")
        
        # Calculate averages (excluding errors)
        avg_letterwise = sum(results[k]["letterwise_ratio"] for k in successful) / len(successful)
        avg_zip = sum(results[k]["zip_ratio"] for k in successful) / len(successful)
        
        print(f"Letter-wise optimal: {avg_letterwise:.2f}x average")
        print(f"ZIP compression: {avg_zip:.2f}x average")
    
    print(f"\nâœ… Compression experiments complete!")
    print(f"Successfully processed: {len(successful)}/{len(samples)} samples")
    
    return results


if __name__ == "__main__":
    run_all_experiments()